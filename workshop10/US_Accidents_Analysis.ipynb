{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can download the in this notebook from: https://www.kaggle.com/sobhanmoosavi/us-accidents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "USacc_df = pd.read_csv('US_Accidents_June20.csv')\n",
    "NJacc_df = USacc_df[USacc_df['State']=='NJ']\n",
    "NJacc_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract year, month, day, weekday information from start time and endtime of accident"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Convert Start_Time and End_Time to datetypes\n",
    "NJacc_df['Start_Time'] = pd.to_datetime(NJacc_df['Start_Time'], errors='coerce')\n",
    "NJacc_df['End_Time'] = pd.to_datetime(NJacc_df['End_Time'], errors='coerce')\n",
    "\n",
    "# Extract year, month, day, hour, weekday and time_duration information\n",
    "NJacc_df['Year']=NJacc_df['Start_Time'].dt.year\n",
    "NJacc_df['Month']=NJacc_df['Start_Time'].dt.strftime('%b')\n",
    "NJacc_df['Day']=NJacc_df['Start_Time'].dt.day\n",
    "NJacc_df['Hour']=NJacc_df['Start_Time'].dt.hour\n",
    "NJacc_df['Weekday']=NJacc_df['Start_Time'].dt.strftime('%a')\n",
    "\n",
    "# Extract the amount of time in the unit of minutes for each accident, round to the nearest integer\n",
    "total_duration='Time_Duration(min)'\n",
    "NJacc_df[total_duration]=round((NJacc_df['End_Time']-NJacc_df['Start_Time'])/np.timedelta64(1,'m'))\n",
    "\n",
    "# Check the dataframe\n",
    "NJacc_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Severity of accident in NJ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NJacc_df.Severity.value_counts().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_autopct(pct):\n",
    "    return ('%1.0f%%' % pct) if pct > 2 else ''\n",
    "\n",
    "plt.pie(NJacc_df.Severity.value_counts(), labels=NJacc_df.Severity.value_counts().index.tolist(),autopct=calc_autopct)\n",
    "plt.title('NJ accident severity')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accident severity is mostly 2 and 3\n",
    "\n",
    "### Daytime versus Nighttime accidents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NJ_curr= NJacc_df['Sunrise_Sunset'].value_counts(normalize=True).round(2)\n",
    "labels = [n if v > 2/100 else '' for n, v in zip(NJ_curr.index, NJ_curr)] \n",
    "plt.pie(NJ_curr, labels = labels,autopct=calc_autopct)\n",
    "plt.title('Daytime versus Nighttime accidents')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "most of the accidents occur in the day\n",
    "\n",
    "### Weekday versus weekend accidents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekdays = [ 'Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun']\n",
    "NJacc_df.groupby('Weekday').count()['ID'].reindex(weekdays).plot(kind='bar')\n",
    "plt.title('Daytime versus Nighttime accidents')\n",
    "plt.xlabel('')\n",
    "plt.ylim(0, 13000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NJ_curr=NJacc_df.groupby('Weekday').count()['ID'].reindex(weekdays)\n",
    "labels = [n if v > 2/100 else '' for n, v in zip(NJ_curr.index, NJ_curr)] \n",
    "plt.pie(NJ_curr, labels = labels,autopct=calc_autopct)\n",
    "plt.title('Weekday versus weekend accidents')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the accidents occur during weekdays\n",
    "\n",
    "### Time of most accidents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NJ_curr=NJacc_df.groupby('Hour').count()['ID'].reindex(np.arange(24)).plot(linestyle='dashed',color='r')\n",
    "plt.xlabel('Hours')\n",
    "plt.ylim(0, 7500)\n",
    "plt.title('Hours of accidents')\n",
    "plt.xticks(np.arange(0, 24, step=2))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the accidents happen during 6-8 and 16-18 i.e., office travel time.\n",
    "\n",
    "\n",
    "### Accidents by county\n",
    "\n",
    "Let's first take a look of the NJ Map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"new-jersey-county-map.gif\" alt=\"Drawing\" style=\"width: 300px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "sns.scatterplot(x='Start_Lng', y='Start_Lat', data=NJacc_df, hue='County')\n",
    "plt.xlabel('Longitude')\n",
    "plt.ylabel('Latitude)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "sns.scatterplot(x='Start_Lng', y='Start_Lat', data=NJacc_df, hue='Severity')\n",
    "plt.xlabel('Longitude')\n",
    "plt.ylabel('Latitude)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see along some path there is higher chances of sever accidents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NJ_curr= NJacc_df['County'].value_counts(normalize=True).round(2)\n",
    "labels = [n if v > 2/100 else '' for n, v in zip(NJ_curr.index, NJ_curr)] \n",
    "plt.pie(NJ_curr, labels = labels,autopct=calc_autopct)\n",
    "plt.title('Accidents countywise')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accidents by city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NJ_curr= NJacc_df['City'].value_counts(normalize=True).round(8)\n",
    "labels = [n if v > 2/100 else '' for n, v in zip(NJ_curr.index, NJ_curr)] \n",
    "plt.pie(NJ_curr, labels = labels,autopct=calc_autopct)\n",
    "plt.title('Accidents citywise')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Streetside of the accidents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NJ_curr= NJacc_df['Side'].value_counts(normalize=True).round(2)\n",
    "labels = [n if v > 2/100 else '' for n, v in zip(NJ_curr.index, NJ_curr)] \n",
    "plt.pie(NJ_curr, labels = labels,autopct=calc_autopct)\n",
    "plt.title('Accidents Side')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Most of the accidents happen on relatively right side of the street"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NJ_curr= NJacc_df['Weather_Condition'].value_counts(normalize=True).round(4)\n",
    "labels = [n if v > 2/100 else '' for n, v in zip(NJ_curr.index, NJ_curr)] \n",
    "plt.pie(NJ_curr, labels = labels,autopct=calc_autopct)\n",
    "plt.title('Accidents Side')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the accident happened on a clear weather day, maybe because most of the day's weather is clear."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict the accident severity with different supervised machine learning algorithms\n",
    "\n",
    "#### Drop rows with negative time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the rows with td<0\n",
    "negtime_outliers=NJacc_df[total_duration]<=0\n",
    "\n",
    "# Set outliers to NAN\n",
    "NJacc_df[negtime_outliers] = np.nan\n",
    "\n",
    "# Drop rows with negative td\n",
    "NJacc_df.dropna(subset=[total_duration],axis=0,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Replace outliers with median values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=3\n",
    "\n",
    "median = NJacc_df[total_duration].median()\n",
    "std = NJacc_df[total_duration].std()\n",
    "outliers = (NJacc_df[total_duration] - median).abs() > std*n\n",
    "\n",
    "# Set outliers to NAN\n",
    "NJacc_df[outliers] = np.nan\n",
    "\n",
    "# Fill NAN with median\n",
    "NJacc_df[total_duration].fillna(median, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_lst=['Source','TMC','Severity','Start_Lng','Start_Lat','Distance(mi)','Side','City','County','State','Timezone','Temperature(F)','Humidity(%)','Pressure(in)', 'Visibility(mi)', 'Wind_Direction','Weather_Condition','Amenity','Bump','Crossing','Give_Way','Junction','No_Exit','Railway','Roundabout','Station','Stop','Traffic_Calming','Traffic_Signal','Turning_Loop','Sunrise_Sunset','Hour','Weekday', 'Time_Duration(min)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NJacc_feature_df=NJacc_df[feature_lst]\n",
    "NJacc_feature_df.dropna(subset=NJacc_feature_df.columns[NJacc_feature_df.isnull().mean()!=0], how='any', axis=0, inplace=True)\n",
    "NJacc_feature_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create dummy variable\n",
    "\n",
    "what is dummay variable?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series(list('abca'))\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.get_dummies(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NJacc_dummy = pd.get_dummies(NJacc_feature_df,drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train and test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Set the target for the prediction\n",
    "target='Severity'\n",
    "\n",
    "# set X and y\n",
    "y = NJacc_dummy[target]\n",
    "X = NJacc_dummy.drop(target, axis=1)\n",
    "\n",
    "# Split the data set into training and testing data sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=21, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Using KNN algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Create a k-NN classifier with 5 neighbors\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# Fit the classifier to the data\n",
    "knn.fit(X_train,y_train)\n",
    "\n",
    "# Predict the labels for the training data X\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "# Get the accuracy score\n",
    "accuracy=accuracy_score(y_test, y_pred)\n",
    "\n",
    "\n",
    "print('KNN accuracy_score: {:.3f}.'.format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "recall=recall_score(y_test, y_pred, average='weighted')\n",
    "print('KNN recall_score: {:.3f}.'.format(recall))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precision attempts to answer the following question:\n",
    "\n",
    "\n",
    "$$\n",
    "\\text{precision} = \\frac{\\text{TP}}{\\text{TP} + \\text{FP}}, \\text{ out of all points predicted to be class } 1, \\text{ what fraction were actually class } 1.\n",
    "$$\n",
    "\n",
    "\n",
    "$$\n",
    "\\text{recall} = \\frac{\\text{TP}}{\\text{TP} + \\text{FN}}, \\text{ out of all the actual data points in class } 1 \\text{, what fraction did the algorithm correctly predict?}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "precision=precision_score(y_test, y_pred, average='weighted')\n",
    "print('KNN precision_score: {:.3f}.'.format(precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "cf_matrix=multilabel_confusion_matrix(y_test, y_pred)\n",
    "print('KNN cf_matrix: ', cf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Using Decision tree algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Instantiate dt_entropy, set 'entropy' as the information criterion\n",
    "decisiontree = DecisionTreeClassifier(max_depth=8, criterion='entropy', random_state=1)\n",
    "\n",
    "\n",
    "# Fit dt_entropy to the training set\n",
    "decisiontree.fit(X_train, y_train)\n",
    "\n",
    "# Use dt_entropy to predict test set labels\n",
    "y_pred= decisiontree.predict(X_test)\n",
    "\n",
    "# Evaluate accuracy_entropy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "\n",
    "# Print accuracy_entropy\n",
    "print('Decision Tree accuracy_score: {:.3f}.'.format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "recall=recall_score(y_test, y_pred, average='weighted')\n",
    "print('Decision tree recall_score: {:.3f}.'.format(recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "precision=precision_score(y_test, y_pred, average='weighted')\n",
    "print('Decision tree precision_score: {:.3f}.'.format(precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "cf_matrix=multilabel_confusion_matrix(y_test, y_pred)\n",
    "print('Decision tree cf_matrix: ', cf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Using Random forest algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest algorithm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "clf=RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "#Train the model using the training sets y_pred=clf.predict(X_test)\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "y_pred=clf.predict(X_test)\n",
    "\n",
    "\n",
    "# Get the accuracy score\n",
    "accuracy=accuracy_score(y_test, y_pred)\n",
    "\n",
    "\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Randon forest algorithm accuracy_score: {:.3f}.\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "recall=recall_score(y_test, y_pred, average='weighted')\n",
    "print('Random forest recall_score: {:.3f}.'.format(recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "precision=precision_score(y_test, y_pred, average='weighted')\n",
    "print('Random forest precision_score: {:.3f}.'.format(precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "cf_matrix=multilabel_confusion_matrix(y_test, y_pred)\n",
    "print('Random forest cf_matrix: ', cf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
